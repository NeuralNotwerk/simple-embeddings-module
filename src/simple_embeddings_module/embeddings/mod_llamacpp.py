# runs llama.cpp's llama-server in embeddings mode and provides embedding functionality
